simulate_streaming_random_sleep:
  min: 0.001  # 0.005
  max: 0.02  # 0.2

llm:
#  default_vendor: wenxin
  default_model: qwen2-72b-instruct
  default_temperature: 0.4
  qianfan:
    models:
      - ERNIE-4.0-8K
      - ERNIE-4.0-8K-0329
      - ERNIE-4.0-8K-Preview-0518
      - ERNIE-3.5-8K-0329
#      - ERNIE-Speed-8K
    default_temperature: 0.4  # (0, 1.0]，官方文档默认 0.8，但Langchain源码里默认 0.95
  zhipu:
    models:
      - GLM-4-0520
      - GLM-4
      - GLM-3-Turbo
    default_temperature: 0.4  # (0, 1.0), 官方默认 0.95
  openai:
    models:
#      - gpt-4
#      - gpt-4o
#      - gpt-3.5-turbo
      - gpt-4o-2024-05-13
      - gpt-4-0125-preview
      - gpt-4-turbo-2024-04-09
      - gpt-3.5-turbo-0125
    organization: org-fC5Q2f4MQIEaTOa3k8vTQu6G
    default_temperature: 0.4  # [0, 2.0]
  deepseek:
    models:
      - deepseek-chat
      - deepseek-coder
    default_temperature: 0.8  # [0, 2]

  bailian:
    models:
      - qwen-max
      - qwen-plus
      - qwen-turbo
      - qwen2-72b-instruct
      - qwen2-57b-a14b-instruct
      - qwen2-7b-instruct
      - qwen2-1.5b-instruct
      - qwen2-0.5b-instruct
      - qwen1.5-110b-chat
      - qwen1.5-72b-chat
      - qwen1.5-32b-chat
      - qwen1.5-14b-chat
      - qwen1.5-7b-chat
      - qwen1.5-1.8b-chat
      - qwen1.5-0.5b-chat
    default_temperature: 0.8  # [0, 2)

lark:
#  default_view_id: vewlGkI2Jp  # all lark bitable's default view id
  default_view_id: vewapHWhJs  # all lark bitable's default view id
